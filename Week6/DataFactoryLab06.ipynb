{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following Skeleton code is from: https://docs.microsoft.com/en-us/azure/data-factory/quickstart-create-data-factory-python\n",
    "Enter: Your Subscription ID, Name of Resource Group, Name of Data Factory, Client ID, Subscription ID, Tenant ID, Location = East US, Azure Storage account: name and key. NOTE: Data Factory only can be created in the East US, East US 2, West Europe regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azure.common.credentials import ServicePrincipalCredentials\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "from azure.mgmt.datafactory import DataFactoryManagementClient\n",
    "from azure.mgmt.datafactory.models import *\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "def print_item(group):\n",
    "    \"\"\"Print an Azure object instance.\"\"\"\n",
    "    print(\"\\tName: {}\".format(group.name))\n",
    "    print(\"\\tId: {}\".format(group.id))\n",
    "    if hasattr(group, 'location'):\n",
    "        print(\"\\tLocation: {}\".format(group.location))\n",
    "    if hasattr(group, 'tags'):\n",
    "        print(\"\\tTags: {}\".format(group.tags))\n",
    "    if hasattr(group, 'properties'):\n",
    "        print_properties(group.properties)\n",
    "\n",
    "def print_properties(props):\n",
    "    \"\"\"Print a ResourceGroup properties instance.\"\"\"\n",
    "    if props and hasattr(props, 'provisioning_state') and props.provisioning_state:\n",
    "        print(\"\\tProperties:\")\n",
    "        print(\"\\t\\tProvisioning State: {}\".format(props.provisioning_state))\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "def print_activity_run_details(activity_run):\n",
    "    \"\"\"Print activity run details.\"\"\"\n",
    "    print(\"\\n\\tActivity run details\\n\")\n",
    "    print(\"\\tActivity run status: {}\".format(activity_run.status))    \n",
    "    if activity_run.status == 'Succeeded':\n",
    "        print(\"\\tNumber of bytes read: {}\".format(activity_run.output['dataRead']))       \n",
    "        print(\"\\tNumber of bytes written: {}\".format(activity_run.output['dataWritten']))           \n",
    "        print(\"\\tCopy duration: {}\".format(activity_run.output['copyDuration']))           \n",
    "    else:\n",
    "        print(\"\\tErrors: {}\".format(activity_run.error['message']))\n",
    "        \n",
    "def print_item(group):\n",
    "    \"\"\"Print an Azure object instance.\"\"\"\n",
    "    print(\"\\tName: {}\".format(group.name))\n",
    "    print(\"\\tId: {}\".format(group.id))\n",
    "    if hasattr(group, 'location'):\n",
    "        print(\"\\tLocation: {}\".format(group.location))\n",
    "    if hasattr(group, 'tags'):\n",
    "        print(\"\\tTags: {}\".format(group.tags))\n",
    "    if hasattr(group, 'properties'):\n",
    "        print_properties(group.properties)\n",
    "\n",
    "def main():\n",
    "\n",
    "# Azure subscription ID\n",
    "    subscription_id = 'putyoursubscriptionIDhere'\n",
    "\n",
    "# This program creates this resource group. If it's an existing resource group, comment out the code that creates the resource group\n",
    "    rg_name = 'DianesRG2'\n",
    "\n",
    "# The data factory name. It must be globally unique.\n",
    "    df_name = 'DianesDF2'\n",
    "\n",
    "# Specify your Active Directory client ID, client secret, and tenant ID\n",
    "    credentials = ServicePrincipalCredentials(client_id='b07ae379-22af-4b19-bb40-c6517c9b3bc3', secret='3IzdVyHiFsLn60bXohzryKUtnsPIed9B015wKynujb4=', tenant='2cc424bd-7c70-4ef2-a8a6-e908829fc5d5')\n",
    "    resource_client = ResourceManagementClient(credentials, subscription_id)\n",
    "    adf_client = DataFactoryManagementClient(credentials, subscription_id)\n",
    "\n",
    "    rg_params = {'location':'eastus'}\n",
    "    df_params = {'location':'eastus'}\n",
    "    \n",
    "# Create the resource group\n",
    "# Comment out if the resource group already exits\n",
    "    resource_client.resource_groups.create_or_update(rg_name, rg_params)\n",
    "    \n",
    "# Create the resource group\n",
    "# Comment out if the resource group already exits\n",
    "    resource_client.resource_groups.create_or_update(rg_name, rg_params)\n",
    "\n",
    "# Create a data factory\n",
    "    df_resource = Factory(location='eastus')\n",
    "    df = adf_client.factories.create_or_update(rg_name, df_name, df_resource)\n",
    "    print_item(df)\n",
    "    while df.provisioning_state != 'Succeeded':\n",
    "        df = adf_client.factories.get(rg_name, df_name)\n",
    "        time.sleep(1)\n",
    "        \n",
    "# Create an Azure Storage linked service\n",
    "    ls_name = 'storageLinkedService'\n",
    "\n",
    "# IMPORTANT: specify the name and key of your Azure Storage account\n",
    "    storage_string = SecureString('DefaultEndpointsProtocol=https;AccountName=dianesnishavablobstorage;AccountKey=MwB+17Qge+ChP43R5vYb2pEtCKKao6aV/ZfKqfefzVcLfhvGHMixI6o6nI8o/zAH1KkJiZ5WKzR7GM7RRjIYaQ==')\n",
    "\n",
    "    ls_azure_storage = AzureStorageLinkedService(connection_string=storage_string)\n",
    "    ls = adf_client.linked_services.create_or_update(rg_name, df_name, ls_name, ls_azure_storage)\n",
    "    print_item(ls) \n",
    "    \n",
    "# Create an Azure blob dataset (input)\n",
    "    ds_name = 'ds_in'\n",
    "    ds_ls = LinkedServiceReference(ls_name)\n",
    "    blob_path= 'adfv2tutorial/input'\n",
    "    blob_filename = 'input.txt'\n",
    "    ds_azure_blob= AzureBlobDataset(ds_ls, folder_path=blob_path, file_name = blob_filename)\n",
    "    ds = adf_client.datasets.create_or_update(rg_name, df_name, ds_name, ds_azure_blob)\n",
    "    print_item(ds)\n",
    "    \n",
    "# Create an Azure blob dataset (output)\n",
    "    dsOut_name = 'ds_out'\n",
    "    output_blobpath = 'adfv2tutorial/output'\n",
    "    dsOut_azure_blob = AzureBlobDataset(ds_ls, folder_path=output_blobpath)\n",
    "    dsOut = adf_client.datasets.create_or_update(rg_name, df_name, dsOut_name, dsOut_azure_blob)\n",
    "    print_item(dsOut)\n",
    "    \n",
    "# Create a copy activity\n",
    "    act_name =  'copyBlobtoBlob'\n",
    "    blob_source = BlobSource()\n",
    "    blob_sink = BlobSink()\n",
    "    dsin_ref = DatasetReference(ds_name)\n",
    "    dsOut_ref = DatasetReference(dsOut_name)\n",
    "    copy_activity = CopyActivity(act_name,inputs=[dsin_ref], outputs=[dsOut_ref], source=blob_source, sink=blob_sink)\n",
    "\n",
    "# Create a pipeline with the copy activity\n",
    "    p_name =  'copyPipeline'\n",
    "    params_for_pipeline = {}\n",
    "    p_obj = PipelineResource(activities=[copy_activity], parameters=params_for_pipeline)\n",
    "    p = adf_client.pipelines.create_or_update(rg_name, df_name, p_name, p_obj)\n",
    "    print_item(p)\n",
    "    \n",
    "# Create a pipeline run.\n",
    "    run_response = adf_client.pipelines.create_run(rg_name, df_name, p_name,\n",
    "        {\n",
    "        }\n",
    "    )\n",
    "    \n",
    "# Monitor the pipeline run\n",
    "    time.sleep(30)\n",
    "    pipeline_run = adf_client.pipeline_runs.get(rg_name, df_name, run_response.run_id)\n",
    "    print(\"\\n\\tPipeline run status: {}\".format(pipeline_run.status))\n",
    "    activity_runs_paged = list(adf_client.activity_runs.list_by_pipeline_run(rg_name, df_name, pipeline_run.run_id, datetime.now() - timedelta(1),  datetime.now() + timedelta(1)))\n",
    "    print_activity_run_details(activity_runs_paged[0])\n",
    "\n",
    "# Start the main method\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
